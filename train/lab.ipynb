{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 模型实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from train import train_test\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20430401  1.29429962  1.26598249 ...  0.46703536 -0.22380128\n",
      "   0.74125771]\n",
      " [ 0.20430401 -0.02658795 -1.18509197 ... -0.7131429  -0.44966586\n",
      "  -0.95415096]\n",
      " [-0.69859663 -1.61165305 -0.50445885 ... -0.41809834 -1.69192101\n",
      "   0.22635582]\n",
      " ...\n",
      " [ 0.20430401  0.89803335  0.91464133 ... -1.30323203  0.22792786\n",
      "  -0.90391663]\n",
      " [-1.47251146  0.23758956 -1.38100443 ...  0.76207992 -1.12725957\n",
      "   0.57799614]\n",
      " [ 0.33328981 -0.15867671 -0.86953556 ... -1.30323203  1.35725072\n",
      "  -0.37645615]]\n",
      "[20:38:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:38:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:38:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:38:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[20:38:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\1GIT\\flight-delay-predict\\train\\lab.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/1GIT/flight-delay-predict/train/lab.ipynb#ch0000002?line=5'>6</a>\u001b[0m \u001b[39m# for max_depth in range(1, 8):\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/1GIT/flight-delay-predict/train/lab.ipynb#ch0000002?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m learning_rate \u001b[39min\u001b[39;00m (\u001b[39m0.1\u001b[39m,\u001b[39m0.15\u001b[39m,\u001b[39m0.2\u001b[39m,\u001b[39m0.25\u001b[39m,\u001b[39m0.3\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/1GIT/flight-delay-predict/train/lab.ipynb#ch0000002?line=7'>8</a>\u001b[0m     ACC, RECALL, PREC, F1 \u001b[39m=\u001b[39m train_test(max_depth\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, learning_rate\u001b[39m=\u001b[39;49mlearning_rate, objective\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmulti:softprob\u001b[39;49m\u001b[39m'\u001b[39;49m, booster\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mgbtree\u001b[39;49m\u001b[39m'\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, min_child_weight\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, gamma\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, subsample\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, colsample_bytree\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m, scale_pos_weight\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/1GIT/flight-delay-predict/train/lab.ipynb#ch0000002?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmax_depth:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m min_child_weight:\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m //\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m,//\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m,//\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m,//\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m5\u001b[39m, learning_rate, ACC, RECALL, PREC, F1))\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/1GIT/flight-delay-predict/train/lab.ipynb#ch0000002?line=9'>10</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mresult.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, newline\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m csvfile:\n",
      "File \u001b[1;32mf:\\1GIT\\flight-delay-predict\\train\\train.py:68\u001b[0m, in \u001b[0;36mtrain_test\u001b[1;34m(max_depth, learning_rate, objective, booster, n_jobs, min_child_weight, gamma, subsample, colsample_bytree, scale_pos_weight)\u001b[0m\n\u001b[0;32m     66\u001b[0m xgb_param = xgb_model.get_xgb_params()\n\u001b[0;32m     67\u001b[0m xgtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n\u001b[1;32m---> 68\u001b[0m cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=xgb_model.get_params()['n_estimators'], nfold=5, metrics='auc', early_stopping_rounds=50,)\n\u001b[0;32m     69\u001b[0m xgb_model.set_params(n_estimators=cvresult.shape[0])\n\u001b[0;32m     70\u001b[0m \n",
      "File \u001b[1;32mc:\\Python3.9\\lib\\site-packages\\xgboost\\training.py:514\u001b[0m, in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    512\u001b[0m booster\u001b[39m.\u001b[39mupdate(i, obj)\n\u001b[1;32m--> 514\u001b[0m should_break \u001b[39m=\u001b[39m callbacks\u001b[39m.\u001b[39;49mafter_iteration(booster, i, dtrain, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    515\u001b[0m res \u001b[39m=\u001b[39m callbacks\u001b[39m.\u001b[39maggregated_cv\n\u001b[0;32m    516\u001b[0m \u001b[39mfor\u001b[39;00m key, mean, std \u001b[39min\u001b[39;00m res:\n",
      "File \u001b[1;32mc:\\Python3.9\\lib\\site-packages\\xgboost\\callback.py:231\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[39m'''Function called after training iteration.'''\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_cv:\n\u001b[1;32m--> 231\u001b[0m     scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49meval(epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_margin)\n\u001b[0;32m    232\u001b[0m     scores \u001b[39m=\u001b[39m _aggcv(scores)\n\u001b[0;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maggregated_cv \u001b[39m=\u001b[39m scores\n",
      "File \u001b[1;32mc:\\Python3.9\\lib\\site-packages\\xgboost\\training.py:229\u001b[0m, in \u001b[0;36m_PackedBooster.eval\u001b[1;34m(self, iteration, feval, output_margin)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, iteration, feval, output_margin):\n\u001b[0;32m    228\u001b[0m     \u001b[39m'''Iterate through folds for eval'''\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     result \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39meval(iteration, feval, output_margin) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcvfolds]\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python3.9\\lib\\site-packages\\xgboost\\training.py:229\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, iteration, feval, output_margin):\n\u001b[0;32m    228\u001b[0m     \u001b[39m'''Iterate through folds for eval'''\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m     result \u001b[39m=\u001b[39m [f\u001b[39m.\u001b[39;49meval(iteration, feval, output_margin) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcvfolds]\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Python3.9\\lib\\site-packages\\xgboost\\training.py:215\u001b[0m, in \u001b[0;36mCVPack.eval\u001b[1;34m(self, iteration, feval, output_margin)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(\u001b[39mself\u001b[39m, iteration, feval, output_margin):\n\u001b[0;32m    214\u001b[0m     \u001b[39m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbst\u001b[39m.\u001b[39;49meval_set(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwatchlist, iteration, feval, output_margin)\n",
      "File \u001b[1;32mc:\\Python3.9\\lib\\site-packages\\xgboost\\core.py:1804\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[1;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[0;32m   1801\u001b[0m evnames \u001b[39m=\u001b[39m c_array(ctypes\u001b[39m.\u001b[39mc_char_p, [c_str(d[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m evals])\n\u001b[0;32m   1802\u001b[0m msg \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p()\n\u001b[0;32m   1803\u001b[0m _check_call(\n\u001b[1;32m-> 1804\u001b[0m     _LIB\u001b[39m.\u001b[39;49mXGBoosterEvalOneIter(\n\u001b[0;32m   1805\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   1806\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   1807\u001b[0m         dmats,\n\u001b[0;32m   1808\u001b[0m         evnames,\n\u001b[0;32m   1809\u001b[0m         c_bst_ulong(\u001b[39mlen\u001b[39;49m(evals)),\n\u001b[0;32m   1810\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(msg),\n\u001b[0;32m   1811\u001b[0m     )\n\u001b[0;32m   1812\u001b[0m )\n\u001b[0;32m   1813\u001b[0m \u001b[39massert\u001b[39;00m msg\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1814\u001b[0m res \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mdecode()  \u001b[39m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 创建csv文件 # 'max_depth', 'learning_rate', 'exp', 'mae', 'mse', 'r2'\n",
    "with open('result.csv', 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['max_depth', 'learning_rate', 'ACC', 'RECALL', 'PREC', 'F1'])\n",
    "\n",
    "for max_depth in range(3, 8):\n",
    "    for min_child_weight in range(1, 7):\n",
    "        ACC, RECALL, PREC, F1 = train_test(max_depth=max_depth, learning_rate=0.5, objective='multi:softmax', booster='gbtree', n_jobs=4, min_child_weight=min_child_weight, gamma=0.1, subsample=0.8, colsample_bytree=0.8)\n",
    "        print('max_depth:{} min_child_weight:{} //{},//{},//{},//{}'.format(max_depth, min_child_weight, ACC, RECALL, PREC, F1))\n",
    "        with open('result.csv', 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([max_depth, min_child_weight, ACC, RECALL, PREC, F1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efa788cb94cb17b6d18a0713a162526dde847b9fce190a5e1ec27ce6e1c4702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
